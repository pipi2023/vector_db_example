# Milvus介绍
## Milvus 简介
Milvus 是一款高性能、可扩展的开源向量数据库，专为处理由深度神经网络和其他机器学习模型生成的大规模嵌入向量而设计，在数据科学和机器学习领域广受欢迎，可以轻松地与其他流行的框架集成，包括 PyTorch 和 TensorFlow，从而可以无缝集成到现有的机器学习工作流程中。自2019年发布以来，Milvus 已成为推荐系统、图像检索、自然语言处理等领域的核心工具。其核心优势包括：
- 高性能：支持万亿级向量数据的毫秒级检索。
- 云原生架构：存储与计算分离，支持弹性扩展。
- 多样化的索引策略：如 HNSW、IVF_FLAT、IVF_PQ 等。
- 混合查询能力：支持向量相似性搜索与标量过滤的联合操作。
## Milvus 高性能原因
Milvus 从设计之初就是一个高效的向量数据库系统。在大多数情况下，Milvus 的性能是其他向量数据库的 2-5 倍。这种高性能是几个关键设计决策的结果：
1. 硬件感知优化：为了让 Milvus 适应各种硬件环境，我们专门针对多种硬件架构和平台优化了其性能，包括 AVX512、SIMD、GPU 和 NVMe SSD。
2. 高级搜索算法：Milvus 支持多种内存和磁盘索引/搜索算法，包括 IVF、HNSW、DiskANN 等，所有这些算法都经过了深度优化。与 FAISS 和 HNSWLib 等流行实现相比，Milvus 的性能提高了 30%-70%。
3. C++ 搜索引擎向量数据库性能的 80% 以上取决于其搜索引擎。由于 C++ 语言的高性能、底层优化和高效资源管理，Milvus 使用 C++ 来处理这一关键组件。最重要的是，Milvus 集成了大量硬件感知代码优化，从汇编级向量到多线程并行化和调度，以充分利用硬件能力。
4. 面向列：Milvus 是面向列的向量数据库系统。其主要优势来自数据访问模式。在执行查询时，面向列的数据库只读取查询中涉及的特定字段，而不是整行，这大大减少了访问的数据量。此外，对基于列的数据的操作可以很容易地进行向量化，从而可以一次性在整个列中应用操作，进一步提高性能。
## Milvus2.0 架构
1. 第 1 层：访问层
访问层由一组无状态代理组成，是系统的前端层，也是用户的终端。由于 Milvus 采用的是大规模并行处理（MPP）架构，代理会对中间结果进行聚合和后处理，然后再将最终结果返回给客户端。
2. 第 2 层：协调器
协调器是 Milvus 的大脑。在任何时刻，整个集群都有一个协调器在工作，负责维护集群拓扑结构、调度所有任务类型并保证集群级一致性。协调器处理的部分任务包括：
    - DDL/DCL/TSO 管理：处理数据定义语言 (DDL) 和数据控制语言 (DCL) 请求，如创建或删除 Collections、分区或索引，以及管理时间戳 Oracle (TSO) 和时间刻度签发。
    - 流服务管理：将先写日志（WAL）与流节点绑定，并为流服务提供服务发现功能。
    - 查询管理：管理查询节点的拓扑结构和负载平衡，并提供和管理服务查询视图，以指导查询路由。
    - 历史数据管理：将压缩和索引建立等离线任务分配给数据节点，并管理数据段和数据视图的拓扑结构。
3. 第 3 层：工作节点
手臂和腿。工作节点是遵从协调器指令的哑执行器。由于存储和计算分离，工作节点是无状态的，部署在 Kubernetes 上时可促进系统扩展和灾难恢复。工作节点有三种类型：
    - 流节点作为碎片级的 "小型大脑"，基于底层 WAL 存储提供碎片级的一致性保证和故障恢复。同时，流节点还负责增长数据查询和生成查询计划。此外，它还负责将增长数据转换为封存（历史）数据。
    - 查询节点从对象存储中加载历史数据，并提供历史数据查询。
    - 数据节点负责离线处理历史数据，如压缩和建立索引。
4. 第 4 层：存储
存储是系统的骨骼，负责数据的持久性。它包括元存储、日志代理和对象存储。
    - 元存储存储元数据快照，如 Collections Schema 和消息消耗检查点。元数据的存储要求极高的可用性、强一致性和事务支持，因此 Milvus 选择 etcd 作为元存储，还使用 etcd 进行服务注册和健康检查。
    - 先写日志（WAL）存储是分布式系统中数据持久性和一致性的基础。在提交任何更改之前，首先要将其记录在日志中，以确保在发生故障时，可以准确恢复到之前的位置。
    - 对象存储用于存储日志快照文件、标量和向量数据的索引文件以及中间查询结果。Milvus 使用 MinIO 作为对象存储，可随时部署在 AWS S3 和 Azure Blob 这两个全球最流行、最具成本效益的存储服务上。然而，对象存储的访问延迟较高，并按查询次数收费。为了提高性能并降低成本，Milvus 计划在基于内存或固态硬盘的缓存池上实现冷热数据分离。 
## Milvus 架构大改原因
1. Tradeoffs
在设计一个分布式系统的过程中，一定会面临一些取舍。比较经典的数据库的取舍方法是 CAP，也就是一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。通常情况下，网络分区容错性不能解决的情况下，用户往往就只能在一致性和可用性之间 tradeoff 。
对于 Milvus 来讲，绝大多数用户更多偏向可用性，对数据的实时可见没有那么高的要求。在此基础上微软提出了：如果网络都是正常的，为了维持一致性，一定要牺牲可用性。比如说跨城服务的情况下，如果要保证一致性的话，那一定需要做跨城读写。这个情况下，Latency 相对来讲一定是比较高的。本身 Milvus 就是一个更加看重 Latency 的系统，因此在大部分情况下，选择去牺牲一定的一致性，也来实现可用性和 Latency 。
除了传统的 CAP 的理论之外，还有另一个 CAP 的 Tradeoff ，就是 Cost、Accuracy 和 Performance。Milvus 也提供了很多种索引的类型，大家可以根据自己在 CAP 方面不同的取舍，选择更好的索引类型和系统参数。
2. 从引擎到数据库
Milvus 本身也会依赖 Faiss、HNSW、Annoy 之类的开源的库。这些库更关注查询的功能和性能。而 Milvus 除了要关注这些内容之外，还需要关注很多其他的东西，比如如何做数据分片，如何保证数据的高可靠性。从用户的角度出发，需要一个更加易用、功能更加强大的组件，而不仅仅是一个更快的库。
3. 拥抱云原生
即如何与其他云的基础设施协同：
    - 过去十几年，传统数据库基本采用 share nothing 的架构。随着  Snowflake 的出现，很多数据库采用了 shared storage，越来越多的数据库开始做存储计算分离。Milvus 利用云上的基础设施去做数据持久化，然后基于本地存储做缓存，这种模这种模式被称为 share something。
    - 利用 Kubernetes 管理执行引擎，利用微服务的模式分拆读、写和其他服务，有利于各个组件分别弹性扩展。Milvus 所有的数据库执行引擎目前与 Docker 和 Kubernetes 适配，包括匹配目前主流的微服务的设计模式。
    - Database as a Service。很多用户不仅关注数据库的功能，还越来越多地关注数据库如何做管理、计费、可视化，数据迁移。 数据库不仅要提供传统的增删改查能力，还提供数据转换、迁移、多租户加密管理、计费、限流、可视化、备份快找等更加多样的服务。
    - 协同一体化。Milvus 本身是一个负责系统，会依赖一些开源系统作为组件， 比如使用 etcd 做元信息的存储。同时，也希望可以跟一些 AI 的 Infra 结合，比如与 Spark 或者 Tensorflow 建立一种上下游的依赖关系。
## Milvus2.0设计理念
1. 日志即数据
日志是一种只能追加、按照时间完全有序的记录序列。在 Milvus 中，有一个全局的中心授时逻辑，发配全局唯一且自增的时间戳。时间戳对事物隔离会有很大的好处，同时，时间戳也可能会用来给数据做定序，比如说一条删除和一条写入的数据，到底哪个时间大，实际上是通过全局唯一的时间戳来定义的。日志序列的用途非常广泛，最广为人知的一个用途就是基于状态机的复制算法，证明了“日志即数据”是很好的工作方式。
2. 表与日志的二象性
日志和数据之间可以相互转换的，它到底有什么作用呢？我们提出，表与日志之间存在二象性。表数据和日志数据是数据的两面，表代表的是有界数据，日志代表的是无界数据。日志可以被转换为表数据，Milvus 通过 TimeTick 分离出处理窗口，并根据处理窗口聚合日志。
3. 日志持久化
分布式数据库日志的存储往往依赖一些复制算法，Milvus 2.0 选择了一条创新道路，依赖 Pub/sub 系统来做日志的存储和持久化。Pub/sub 系统是类似 Kafka 或者 Pulsar 的消息队列，有这么一套系统后，其他系统的角色就变成了日志的消费者。这套系统的存在将日志和服务器完全解耦，保证 Milvus 本身是没有状态的，这样可以提升故障恢复速度。
4. 集市架构
基于这套日志系统，可以设计“集市架构”，核心解决的问题是如何高效地扩展一个系统。它是一种松散的耦合，就好像大家都处在同一个环境中，但是每个人不太关心彼此在做什么事情。用户把原始数据通过各种类型的转换，才可以转化成 embedding 数据，也可以转化成 Semi-structured data。比如说一些 text 也可以转化成 Structured data，类似于 relational model。